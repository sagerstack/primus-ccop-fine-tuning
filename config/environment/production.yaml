# Production Environment Configuration
app:
  name: "CCoP Fine-tuning - Production"
  environment: "production"
  debug: false
  log_level: "INFO"

# Model Configuration
models:
  llama_primus:
    name: "trendmicro-ailab/Llama-Primus-Reasoning"
    device: "auto"
    torch_dtype: "float16"
    load_in_8bit: true  # Enable for production to save memory

  gpt5:
    model: "gpt-5"
    api_base: "https://api.openai.com/v1"
    max_tokens: 2048
    temperature: 0.1

  deepseek:
    model: "deepseek-v3"
    api_base: "https://api.deepseek.com/v1"
    max_tokens: 2048
    temperature: 0.1

# Data Configuration
data:
  benchmark_datasets:
    phase2_baseline: "data/benchmark/phase2_baseline_40_cases.json"
    phase3_comprehensive: "data/benchmark/phase3_comprehensive_170_cases.json"
    production_validation: "data/benchmark/production_validation_420_cases.json"

  ccop_clauses: "data/raw/ccop_clauses/"
  vulnerable_code: "data/raw/vulnerable_code/"
  infrastructure_configs: "data/raw/infrastructure_configs/"

# Evaluation Configuration
evaluation:
  benchmarks:
    phase2: ["B1", "B2", "B3", "B4", "B5", "B6"]
    phase3: ["B1", "B2", "B3", "B4", "B5", "B6", "B7", "B8", "B9", "B10", "B11", "B12"]
    production: ["B1", "B2", "B3", "B4", "B5", "B6", "B7", "B8", "B9", "B10", "B11", "B12", "B13", "B14", "B15", "B16", "B17", "B18", "B19"]

  scoring:
    weights:
      compliance: 0.35
      code_scanning: 0.30
      advanced: 0.15
      safety: 0.15
      performance: 0.05

  targets:
    overall_score_min: 0.50  # 50% minimum for production
    overall_score_target: 0.85  # 85% target for production
    hallucination_rate_max: 0.0  # Zero hallucinations allowed

# Google Cloud Configuration
google_cloud:
  storage_bucket: "ccop-finetuning-prod"
  drive_folder_id: null  # Will be set during setup

  authentication:
    use_service_account: true
    credentials_path: "config/service-account.json"

  scopes:
    - "https://www.googleapis.com/auth/drive"
    - "https://www.googleapis.com/auth/cloud-platform"

# Colab Integration
colab:
  github_repo: "https://github.com/sagerstack/primus-ccop-fine-tuning.git"
  branch: "main"
  notebooks_path: "/content/studio-ssdlc/colab/"
  data_path: "/content/studio-ssdlc/data/"
  results_path: "/content/studio-ssdlc/benchmarks/results/"

# Logging Configuration
logging:
  version: 1
  disable_existing_loggers: false
  formatters:
    default:
      format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    console:
      class: "logging.StreamHandler"
      level: "INFO"
      formatter: "default"
      stream: "ext://sys.stdout"
  loggers:
    "":
      level: "INFO"
      handlers: ["console"]
      propagate: false