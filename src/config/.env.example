# CCoP 2.0 Model Evaluation Framework - Environment Configuration

# ============================================================================
# Ollama Configuration
# ============================================================================
CCOP_OLLAMA_HOST=http://localhost:11434
CCOP_OLLAMA_TIMEOUT=300

# ============================================================================
# Model Configuration
# ============================================================================
CCOP_MODEL_NAME=primus-reasoning
CCOP_MODEL_HF_REPO=trendmicro-ailab/Llama-Primus-Reasoning
CCOP_MODEL_QUANTIZATION=Q5_K_M  # Options: Q4_K_M, Q5_K_M, Q6_K, Q8_0
CCOP_MODEL_CACHE_DIR=~/.cache/ccop-models

# ============================================================================
# Evaluation Configuration
# ============================================================================
CCOP_TEST_CASES_DIR=data/test-cases
CCOP_RESULTS_DIR=results/evaluations
CCOP_MAX_CONCURRENT_EVALUATIONS=3

# ============================================================================
# LLM Inference Parameters
# ============================================================================
CCOP_DEFAULT_TEMPERATURE=0.7
CCOP_DEFAULT_TOP_P=0.9
CCOP_DEFAULT_TOP_K=40
CCOP_DEFAULT_MAX_TOKENS=1024
CCOP_CONTEXT_LENGTH=4096

# ============================================================================
# Logging Configuration
# ============================================================================
CCOP_LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
CCOP_LOG_FORMAT=json  # Options: json, console
CCOP_LOG_FILE=logs/ccop-eval.log

# ============================================================================
# HuggingFace Configuration
# ============================================================================
# HF_TOKEN=your_huggingface_token_here  # Optional: for private models or faster downloads
# HF_HOME=~/.cache/huggingface

# ============================================================================
# Development/Debug Configuration
# ============================================================================
CCOP_DEBUG=false
CCOP_MOCK_MODE=false  # Set to true to use mock gateway instead of real Ollama
